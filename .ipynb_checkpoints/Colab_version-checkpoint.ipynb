{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RobiOneKeno6i/multiplets/blob/main/Colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ejgkpd7opbcR"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZNyx3BXoHdo",
    "outputId": "d71cf9b9-a20f-4fdd-a556-91f9e185501e"
   },
   "outputs": [],
   "source": [
    "!pip install portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHcPiDhwAZtV"
   },
   "source": [
    "round(#,6) has been added to cope with low precision of standard single float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdsy7R2kjETP",
    "outputId": "9a6fd29f-3c4a-49d0-955a-9618232d1f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading catalogue data ...\n",
      "records, length (337254, 6)\n",
      "local cartesian coordinates...  (337254, 6)\n",
      "magnitude subset of  95807 events...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools \n",
    "import math\n",
    "import collections\n",
    "\n",
    "import reproducible\n",
    "\n",
    "# create a reproducible.Context instance, that will hold all the\n",
    "# tracked data.\n",
    "context = reproducible.Context()\n",
    "\n",
    "# recording git repository state\n",
    "# here we are okay with running our code with uncommitted changes, but\n",
    "# we record a diff of the changes in the tracked data.\n",
    "context.add_repo(path='.', allow_dirty=True, diff=True)\n",
    "\n",
    "# recording parameters; this is not necessarily needed, as the code state\n",
    "# is recorded, but it is convenient.\n",
    "#seed = 1\n",
    "#random.seed(seed)\n",
    "#context.add_data('seed', seed)\n",
    "\n",
    "# add_data return the provided value (here 10), so you can do this:\n",
    "#n = reproducible.add_data('n', 10)\n",
    "#results = walk(n)\n",
    "\n",
    "# recording the SHA1 hash of the output file\n",
    "#context.add_file('results.pickle', category='output')\n",
    "\n",
    "# you can examine the tracked data and add or remove from it at any moment\n",
    "# with `context.data`: it is a simple dictionary. For instance, the\n",
    "# cpu info is quite detailed. Let's remove it to keep the yaml output short.\n",
    "#context.data.pop('cpuinfo')\n",
    "\n",
    "# exporting the provenance data to disk\n",
    "context.export_yaml('results_jupyter_prov.yaml')\n",
    "\n",
    "\n",
    "# class for GRAPHS operations and graphics\n",
    "# https://networkx.org/documentation/stable/reference/index.html\n",
    "import networkx as nx\n",
    "\n",
    "DGoptions = {\n",
    "    'node_color': 'orange',\n",
    "    'node_size': 400,\n",
    "    'width': 1,\n",
    "}\n",
    "\n",
    "# class for operation on INTERVALS  \n",
    "# https://pypi.org/project/portion/\n",
    "import portion as P  \n",
    "\n",
    "# useful functions definitions\n",
    "def subsets(s, n):\n",
    "    return list(itertools.combinations(s, n)) \n",
    "\n",
    "def flatten(s):\n",
    "    return list(itertools.chain.from_iterable(s))\n",
    "  \n",
    "# Gardner Knopoff table functions for distances (km) and time (yrs)\n",
    "from scipy import interpolate\n",
    "\n",
    "gardnerknopofflist = [[2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, \n",
    "     8], [19.5, 22.5, 26, 30, 35, 40, 47, 54, 61, 70, 81, 94],[6, \n",
    "     11.5, 22, 42, 83, 155, 290, 510, 790, 915, 960, 985]]\n",
    "\n",
    "def gkr(mag):\n",
    "    return np.interp(mag,gardnerknopofflist[0],gardnerknopofflist[1])\n",
    "\n",
    "def gkt(mag):\n",
    "    return np.interp(mag,gardnerknopofflist[0], [x/365 for x in gardnerknopofflist[2]])\n",
    "\n",
    "def gkr2(m1, m2, flag):\n",
    "    if flag == \"sum\":\n",
    "        return gkr(m1)+gkr(m2)\n",
    "    elif flag == \"max\":\n",
    "        return max(gkr(m1),gkr(m2))\n",
    "    elif flag==\"1st\":\n",
    "        return gkr(m1)\n",
    "    else:\n",
    "        return (m1,m2,gkr(m1),gkr(m2))\n",
    "    \n",
    "# sphere to plane projection  GEO2XY\n",
    "def g2x(listarod):\n",
    "    [t,lat,lon,dep,mag,id]=listarod\n",
    "    R=6367\n",
    "    alfa=180/math.pi\n",
    "    x=(R*(lon - lon0)*math.cos(lat/alfa))/alfa - (R*(lon-lon0)**3*math.cos(lat/alfa)*math.sin(lat/alfa)**2)/(6.*alfa**3)\n",
    "    y=((lat - lat0)*R)/alfa + ((lon - lon0)**2*R*math.sin((2.*lat)/alfa))/(4.*alfa**2)\n",
    "    return [t,x,y,dep,mag,id]\n",
    "\n",
    "\n",
    "# seismic catalogue import with numpy\n",
    "\n",
    "#catfile='absolute_catalogue_file_path'\n",
    "catfile='Simulated_100k_005-02-2_geo.txt'\n",
    "\n",
    "print('loading catalogue data ...')\n",
    "raw=np.loadtxt(catfile)\n",
    "\n",
    "print('records, length', raw.shape)\n",
    "\n",
    "lat0=np.mean(raw[:,1])\n",
    "lon0=np.mean(raw[:,2])\n",
    "\n",
    "orig=np.apply_along_axis(g2x,1,raw)\n",
    "print('local cartesian coordinates... ',orig.shape)\n",
    "#print(orig)\n",
    "\n",
    "# variables (RE)-INIZIALISATION\n",
    "\n",
    "removed = \"GK\"\n",
    "gkrad = \"sum\"; \n",
    "data = orig\n",
    "multipletti = []\n",
    "n = 0\n",
    "catalogo = 0\n",
    "rj = 0\n",
    "\n",
    "magthresh=5.5\n",
    "dmplus=.4\n",
    "dmminus=.6\n",
    "\n",
    "\n",
    "########################  data subset PRE-FILTERING ######################\n",
    "\n",
    "indexes=np.arange(len(orig))\n",
    "orig=np.concatenate((orig[:,:-1], np.atleast_2d(indexes).T), axis=1)\n",
    "#data=orig[np.where(orig[:,4] >= magthresh - dmminus)]\n",
    "#mp=orig[np.where(orig[:,4] >= (magthresh - dmminus)),-1][0].astype(int)\n",
    "\n",
    "# round necessary to overcome low precision in python default float in subtraction\n",
    "evthr=round(magthresh - dmminus,6)\n",
    "mp=orig[np.where(orig[:,4] >= evthr),-1][0].astype(int)\n",
    "mplen=len(mp)\n",
    "maxmp=mp[-1]\n",
    "data=orig\n",
    "\n",
    "# put path for intermediate computations data (not strictly necessary: debug purposes)\n",
    "np.savetxt('python_orig.txt', data, fmt='%10.5f', delimiter='\\t', newline='\\n', header='', footer='', comments='# ', encoding=None)\n",
    "np.savetxt('python_mp.txt', mp, fmt='%d')\n",
    "\n",
    "# indexes=np.arange(len(data))\n",
    "# re-indexing on extracted sub-list\n",
    "# data=np.concatenate((data[:,:-1], np.atleast_2d(indexes).T), axis=1)\n",
    "\n",
    "print('magnitude subset of ', mplen, 'events...')\n",
    "\n",
    "\n",
    "#*************** MAIN LOOP **************\n",
    "#debug=open('/Volumes/GoogleDrive/Il mio Drive/Colab Notebooks/multiplette/dati/python_debug.txt', 'w')\n",
    "\n",
    "while(len(mp)>1):\n",
    "    intersezioni=[]\n",
    "    gkconnected=[]\n",
    "    gkconnectedlists=[]\n",
    "    vertexlist=[]\n",
    "\n",
    "\n",
    "    ######################## PIVOT point search ########################\n",
    "\n",
    "    while(mp[n] != mp[-1] and data[mp[n], 4] < magthresh):\n",
    "        n+=1\n",
    "\n",
    "    j=mp[n]\n",
    "    mpback=mp\n",
    "    #print(j, file=debug)\n",
    "    \n",
    "    #if j==323387:\n",
    "    #    print('breakpoint')\n",
    "\n",
    "    mp=np.delete(mp,slice(0,n))\n",
    "    n=0\n",
    "\n",
    "    ######################## POOL GKt search ########################\n",
    "    connessi=[]\n",
    "    pool = [[mp[n], data[mp[n]]]]\n",
    "    intpool = P.closed( data[mp[n],0], data[mp[n],0] + gkt(data[mp[n],4]))\n",
    "\n",
    "    while(mp[n] != mp[-1]):\n",
    "        nextintpool=intpool.union(P.closed(data[mp[n+1],0], data[mp[n+1],0] + gkt(data[mp[n+1],4])))\n",
    "\n",
    "        if(mp[n] != mp[-1] and nextintpool.atomic):\n",
    "            n=n+1\n",
    "            intpool=nextintpool\n",
    "            pool.append([mp[n],data[mp[n]]])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    ######################## pool pairs generation and test over 3 criteria ########################\n",
    "    if len(pool)>1:\n",
    "        couples = subsets(pool, 2)\n",
    "\n",
    "\n",
    "        # couples [[id1,array(t1,x1,y1,z1,mag1,idbase1)], [id2,array(t2,...)]\n",
    "        for t in couples:\n",
    "            idp=[t[0][0],t[1][0]]\n",
    "            gkx_flag = np.linalg.norm(np.array([t[0][1][1:4]])-np.array([t[1][1][1:4]])) <= gkr2(t[0][1][4],t[1][1][4], gkrad)\n",
    "            gkt_flag = round(t[1][1][0] - t[0][1][0],6) <= gkt(t[0][1][4])\n",
    "            mag_flag = -dmplus <= round(data[j][4]-t[1][1][4],6) <= dmminus\n",
    "\n",
    "            # intersezioni (X,t,mag)\n",
    "            if gkx_flag and gkt_flag and mag_flag:\n",
    "                intersezioni.append(idp)\n",
    "                vertexlist = list(set(itertools.chain.from_iterable(intersezioni)))\n",
    "\n",
    "            # intersezioni (X,t)\n",
    "            if gkx_flag and gkt_flag:\n",
    "                gkconnectedlists.append(idp)\n",
    "                gkconnected = list(set(itertools.chain.from_iterable(gkconnectedlists)))\n",
    "\n",
    "            # print(idp, gkx_flag, gkt_flag, mag_flag)\n",
    "\n",
    "\n",
    "        ####################  GRAPH generation for multiplets count ###################\n",
    "        DG = nx.DiGraph()\n",
    "        DG.add_edges_from(intersezioni)\n",
    "        # nx.draw(DG,with_labels=True, **DGoptions)  # networkx draw()\n",
    "        # plt.draw()  # pyplot draw()\n",
    "\n",
    "        #connessi = []\n",
    "        if j in vertexlist:\n",
    "            connessi=list(nx.single_source_shortest_path(DG,j).keys())\n",
    "\n",
    "    ######################## remove elements from mp and reset for a new pivot search ########################\n",
    "\n",
    "    if len(connessi)>1:\n",
    "        multipletti.append(connessi)\n",
    "\n",
    "    lmpold=len(mp)\n",
    "\n",
    "    if removed == \"GK\":\n",
    "        #mp1=[x for x in mp if x not in gkconnected]\n",
    "        mp=sorted(list(set(mp)-set(gkconnected)))\n",
    "    elif removed == \"GK-Mag\":\n",
    "        mp=sorted(list(set(mp)-set(intersezioni)))\n",
    "\n",
    "    mp=sorted(list(set(mp)-set([j])))\n",
    "    n=0\n",
    "\n",
    "print('# multiplette', len(multipletti))\n",
    "\n",
    "# lengths count\n",
    "cnt = collections.Counter()\n",
    "for mlen in [len(x) for x in multipletti]:\n",
    "    cnt[mlen] += 1\n",
    "\n",
    "\n",
    "print('catalogue file: ',catfile)\n",
    "print('threshold magnitude:', magthresh, '(-', dmminus, ') e (+', dmplus,')' )\n",
    "print('Extracted a subset of', mplen, 'events from a catalogue of ', len(orig), 'events\\n')\n",
    "print('algorithm parameters: removal (',removed,') interaction radii function (',gkrad,')')\n",
    "print('# multiplets:', len(multipletti))\n",
    "print('# counts: ',cnt)\n",
    "\n",
    "# put path for complete output file save\n",
    "f=open('python_vs_out_new.txt', 'w')\n",
    "print('catalogue file: ',catfile, file=f)\n",
    "print('threshold magnitude:', magthresh, '(-', dmminus, ') e (+', dmplus,')' , file=f)\n",
    "print('Extracted a subset of', mplen, 'events from a catalogue of ', len(orig), 'events\\n', file=f)\n",
    "print('algorithm parameters: removal (',removed,') interaction radii function (',gkrad,')', file=f)\n",
    "print('# multiplets:', len(multipletti), file=f)\n",
    "print('# counts: ',cnt, file=f)\n",
    "print(multipletti, file=f)\n",
    "f.close()\n",
    "#debug.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1H1u51ooE5K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAuGv20Em1-x"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMLaB4CZfP7iW7IC7ZGCRuF",
   "include_colab_link": true,
   "mount_file_id": "1OiPPVQ97yG_cY1sYWKSJ-0EAsdrMkICj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
